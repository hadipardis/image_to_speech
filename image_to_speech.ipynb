{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0P8D2mOesBJ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain import HuggingFaceHub\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hL9aNs19fD8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert an image to text using an image captioning model\n",
        "def img2text(url):\n",
        "  pipe = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
        "  text = pipe(url)[0][\"generated_text\"]\n",
        "  return text"
      ],
      "metadata": {
        "id": "beVLjbdJfR2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img2text(\"three_persons.jpg\"))"
      ],
      "metadata": {
        "id": "Kg63jxxmni34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We now define our LLM\n",
        "repo_id = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "hf_token = \"YOUR HF API Key\"\n",
        "llm = HuggingFaceHub(huggingfacehub_api_token=hf_token,\n",
        "                     repo_id=repo_id,\n",
        "                     verbose=False,\n",
        "                     model_kwargs={\"temperature\":0.1, \"max_new_tokens\":1500})\n",
        "\n"
      ],
      "metadata": {
        "id": "wf2FbIPmhcz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(scenario, llm):\n",
        "  template= \"\"\"You are a story teller.\n",
        "               You get a scenario as an input text, and generates a short story out of it.\n",
        "               Context: {scenario}\n",
        "               Story:\n",
        "               \"\"\"\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"scenario\"])\n",
        "  #Let's create our LLM chain now\n",
        "  chain = LLMChain(prompt=prompt, llm=llm)\n",
        "  story = chain.predict(scenario=scenario)\n",
        "  return story\n"
      ],
      "metadata": {
        "id": "LS5bcDWZgFIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scenario = \"A man is walking in a dark street.\"\n",
        "print(generate_story(scenario, llm))"
      ],
      "metadata": {
        "id": "BX3LuYkRisN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "def text2speech(text):\n",
        "  API_URL = \"https://api-inference.huggingface.co/models/facebook/mms-tts-eng\"\n",
        "  headers = {\"Authorization\": \"Bearer YOUR HF API Key\"}\n",
        "  payload = {\"inputs\": text}\n",
        "  response = requests.post(API_URL, headers=headers, json=payload)\n",
        "  return response.content"
      ],
      "metadata": {
        "id": "Z-09duqnlb4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_file = \"three_persons.jpg\"\n",
        "img = plt.imread(img_file)\n",
        "plt.imshow(img)\n",
        "\n",
        "scenario = img2text(img_file)\n",
        "print(scenario)\n",
        "story = generate_story(scenario, llm)\n",
        "print(story)\n",
        "audio_bytes = text2speech(story)\n",
        "\n",
        "# You can access the audio with IPython.display for example\n",
        "from IPython.display import Audio\n",
        "Audio(audio_bytes)"
      ],
      "metadata": {
        "id": "-rmjka2BolCC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}